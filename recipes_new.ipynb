{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 – Recommender Systems\n",
    "\n",
    "**Name:**  \n",
    "**PID:**  \n",
    "**Dataset:** Food.com Recipes & Reviews (McAuley Lab Recommender Systems Datasets)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Dataset Selection & Exploratory Analysis\n",
    "\n",
    "We use the **Food.com Recipes & Reviews** dataset from Julian McAuley’s Recommender Systems and Personalization Datasets page.\n",
    "\n",
    "This dataset contains:\n",
    "- ~231k recipes  \n",
    "- ~226k users  \n",
    "- ~1.1M reviews (user–recipe interactions)  \n",
    "\n",
    "Each interaction includes:\n",
    "- `user_id`, `recipe_id`\n",
    "- integer `rating` from 1 to 5\n",
    "- review `date`\n",
    "\n",
    "Each recipe includes:\n",
    "- `minutes`, `n_steps`, `n_ingredients`\n",
    "- `nutrition` (list of [calories, total_fat, sugar, sodium, protein, sat_fat, carbs])\n",
    "- title, description, ingredients, steps, tags, etc.\n",
    "\n",
    "We will:\n",
    "- Load recipes and interactions\n",
    "- Compute basic statistics: number of users/items/interactions, sparsity, rating distribution, time span\n",
    "- Use these to motivate our **features** and **predictive task**\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c91afba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.conda/lib/python3.11/site-packages (25.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in ./.conda/lib/python3.11/site-packages (2.3.5)\n",
      "Requirement already satisfied: pandas in ./.conda/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in ./.conda/lib/python3.11/site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in ./.conda/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.conda/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.conda/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.conda/lib/python3.11/site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.conda/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.conda/lib/python3.11/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.conda/lib/python3.11/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in ./.conda/lib/python3.11/site-packages (2.9.1)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/torchvision-0.2.0-py2.py3-none-any.whl (48 kB)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torchaudio (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torchaudio\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipykernel in ./.conda/lib/python3.11/site-packages (7.1.0)\n",
      "Requirement already satisfied: appnope>=0.1.2 in ./.conda/lib/python3.11/site-packages (from ipykernel) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./.conda/lib/python3.11/site-packages (from ipykernel) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.conda/lib/python3.11/site-packages (from ipykernel) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./.conda/lib/python3.11/site-packages (from ipykernel) (9.7.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in ./.conda/lib/python3.11/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.conda/lib/python3.11/site-packages (from ipykernel) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.conda/lib/python3.11/site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in ./.conda/lib/python3.11/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging>=22 in ./.conda/lib/python3.11/site-packages (from ipykernel) (25.0)\n",
      "Requirement already satisfied: psutil>=5.7 in ./.conda/lib/python3.11/site-packages (from ipykernel) (7.1.3)\n",
      "Requirement already satisfied: pyzmq>=25 in ./.conda/lib/python3.11/site-packages (from ipykernel) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in ./.conda/lib/python3.11/site-packages (from ipykernel) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./.conda/lib/python3.11/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator>=4.3.2 in ./.conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in ./.conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in ./.conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in ./.conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in ./.conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in ./.conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (4.15.0)\n",
      "Requirement already satisfied: wcwidth in ./.conda/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.conda/lib/python3.11/site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel) (0.8.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/lib/python3.11/site-packages (from jupyter-client>=8.0.0->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.conda/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.5.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.conda/lib/python3.11/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.conda/lib/python3.11/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in ./.conda/lib/python3.11/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install numpy pandas matplotlib seaborn\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "68f47d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arriba   baked winter squash mexican style</td>\n",
       "      <td>137739</td>\n",
       "      <td>55</td>\n",
       "      <td>47892</td>\n",
       "      <td>2005-09-16</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['make a choice and proceed with recipe', 'dep...</td>\n",
       "      <td>autumn is my favorite time of year to cook! th...</td>\n",
       "      <td>['winter squash', 'mexican seasoning', 'mixed ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a bit different  breakfast pizza</td>\n",
       "      <td>31490</td>\n",
       "      <td>30</td>\n",
       "      <td>26278</td>\n",
       "      <td>2002-06-17</td>\n",
       "      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>['preheat oven to 425 degrees f', 'press dough...</td>\n",
       "      <td>this recipe calls for the crust to be prebaked...</td>\n",
       "      <td>['prepared pizza crust', 'sausage patty', 'egg...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all in the kitchen  chili</td>\n",
       "      <td>112140</td>\n",
       "      <td>130</td>\n",
       "      <td>196586</td>\n",
       "      <td>2005-02-25</td>\n",
       "      <td>['time-to-make', 'course', 'preparation', 'mai...</td>\n",
       "      <td>[269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>['brown ground beef in large pot', 'add choppe...</td>\n",
       "      <td>this modified version of 'mom's' chili was a h...</td>\n",
       "      <td>['ground beef', 'yellow onions', 'diced tomato...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alouette  potatoes</td>\n",
       "      <td>59389</td>\n",
       "      <td>45</td>\n",
       "      <td>68585</td>\n",
       "      <td>2003-04-14</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['place potatoes in a large pot of lightly sal...</td>\n",
       "      <td>this is a super easy, great tasting, make ahea...</td>\n",
       "      <td>['spreadable cheese with garlic and herbs', 'n...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amish  tomato ketchup  for canning</td>\n",
       "      <td>44061</td>\n",
       "      <td>190</td>\n",
       "      <td>41706</td>\n",
       "      <td>2002-10-25</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>['mix all ingredients&amp; boil for 2 1 / 2 hours ...</td>\n",
       "      <td>my dh's amish mother raised him on this recipe...</td>\n",
       "      <td>['tomato juice', 'apple cider vinegar', 'sugar...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name      id  minutes  \\\n",
       "0  arriba   baked winter squash mexican style  137739       55   \n",
       "1            a bit different  breakfast pizza   31490       30   \n",
       "2                   all in the kitchen  chili  112140      130   \n",
       "3                          alouette  potatoes   59389       45   \n",
       "4          amish  tomato ketchup  for canning   44061      190   \n",
       "\n",
       "   contributor_id   submitted  \\\n",
       "0           47892  2005-09-16   \n",
       "1           26278  2002-06-17   \n",
       "2          196586  2005-02-25   \n",
       "3           68585  2003-04-14   \n",
       "4           41706  2002-10-25   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "1  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
       "2  ['time-to-make', 'course', 'preparation', 'mai...   \n",
       "3  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "4  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "\n",
       "                                    nutrition  n_steps  \\\n",
       "0       [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
       "1   [173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]        9   \n",
       "2  [269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]        6   \n",
       "3   [368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]       11   \n",
       "4   [352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]        5   \n",
       "\n",
       "                                               steps  \\\n",
       "0  ['make a choice and proceed with recipe', 'dep...   \n",
       "1  ['preheat oven to 425 degrees f', 'press dough...   \n",
       "2  ['brown ground beef in large pot', 'add choppe...   \n",
       "3  ['place potatoes in a large pot of lightly sal...   \n",
       "4  ['mix all ingredients& boil for 2 1 / 2 hours ...   \n",
       "\n",
       "                                         description  \\\n",
       "0  autumn is my favorite time of year to cook! th...   \n",
       "1  this recipe calls for the crust to be prebaked...   \n",
       "2  this modified version of 'mom's' chili was a h...   \n",
       "3  this is a super easy, great tasting, make ahea...   \n",
       "4  my dh's amish mother raised him on this recipe...   \n",
       "\n",
       "                                         ingredients  n_ingredients  \n",
       "0  ['winter squash', 'mexican seasoning', 'mixed ...              7  \n",
       "1  ['prepared pizza crust', 'sausage patty', 'egg...              6  \n",
       "2  ['ground beef', 'yellow onions', 'diced tomato...             13  \n",
       "3  ['spreadable cheese with garlic and herbs', 'n...             11  \n",
       "4  ['tomato juice', 'apple cider vinegar', 'sugar...              8  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For pretty printing\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "# === Adjust these paths to where you store the dataset ===\n",
    "RECIPES_PATH = \"RAW_recipes.csv\"\n",
    "INTERACTIONS_PATH = \"RAW_interactions.csv\"\n",
    "\n",
    "recipes = pd.read_csv(RECIPES_PATH)\n",
    "interactions = pd.read_csv(INTERACTIONS_PATH)\n",
    "\n",
    "recipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "08340db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38094</td>\n",
       "      <td>40893</td>\n",
       "      <td>2003-02-17</td>\n",
       "      <td>4</td>\n",
       "      <td>Great with a salad. Cooked on top of stove for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1293707</td>\n",
       "      <td>40893</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>5</td>\n",
       "      <td>So simple, so delicious! Great for chilly fall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8937</td>\n",
       "      <td>44394</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>This worked very well and is EASY.  I used not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126440</td>\n",
       "      <td>85009</td>\n",
       "      <td>2010-02-27</td>\n",
       "      <td>5</td>\n",
       "      <td>I made the Mexican topping and took it to bunk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57222</td>\n",
       "      <td>85009</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>Made the cheddar bacon topping, adding a sprin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  recipe_id        date  rating  \\\n",
       "0    38094      40893  2003-02-17       4   \n",
       "1  1293707      40893  2011-12-21       5   \n",
       "2     8937      44394  2002-12-01       4   \n",
       "3   126440      85009  2010-02-27       5   \n",
       "4    57222      85009  2011-10-01       5   \n",
       "\n",
       "                                              review  \n",
       "0  Great with a salad. Cooked on top of stove for...  \n",
       "1  So simple, so delicious! Great for chilly fall...  \n",
       "2  This worked very well and is EASY.  I used not...  \n",
       "3  I made the Mexican topping and took it to bunk...  \n",
       "4  Made the cheddar bacon topping, adding a sprin...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03f2a8c",
   "metadata": {},
   "source": [
    "### 1.1 Basic dataset statistics\n",
    "We first compute:\n",
    "- Number of users\n",
    "- Number of recipes\n",
    "- Number of interactions\n",
    "- Density / sparsity of the user–item matrix\n",
    "- Rating distribution\n",
    "- Time period covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0e30862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 226570\n",
      "Number of recipes (items): 231637\n",
      "Number of interactions (reviews): 1132367\n",
      "Sparsity of user–item matrix: 0.999978\n"
     ]
    }
   ],
   "source": [
    "n_users = interactions[\"user_id\"].nunique()\n",
    "n_items = interactions[\"recipe_id\"].nunique()\n",
    "n_interactions = len(interactions)\n",
    "\n",
    "print(\"Number of users:\", n_users)\n",
    "print(\"Number of recipes (items):\", n_items)\n",
    "print(\"Number of interactions (reviews):\", n_interactions)\n",
    "\n",
    "# Sparsity of the user–item matrix\n",
    "total_possible = n_users * n_items\n",
    "sparsity = 1 - (n_interactions / total_possible)\n",
    "print(f\"Sparsity of user–item matrix: {sparsity:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4ab1ed07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating distribution:\n",
      "rating\n",
      "0     60847\n",
      "1     12818\n",
      "2     14123\n",
      "3     40855\n",
      "4    187360\n",
      "5    816364\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rating distribution\n",
    "rating_counts = interactions[\"rating\"].value_counts().sort_index()\n",
    "print(\"Rating distribution:\")\n",
    "print(rating_counts)\n",
    "\n",
    "plt.figure()\n",
    "rating_counts.plot(kind=\"bar\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Rating Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0ff2d040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest review date: 2000-01-25 00:00:00\n",
      "Latest review date: 2018-12-20 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Time period covered\n",
    "interactions[\"date\"] = pd.to_datetime(interactions[\"date\"])\n",
    "print(\"Earliest review date:\", interactions[\"date\"].min())\n",
    "print(\"Latest review date:\", interactions[\"date\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b429523",
   "metadata": {},
   "source": [
    "### 1.2 Interesting phenomena from exploratory analysis (to discuss in writeup)\n",
    "\n",
    "Based on the above:\n",
    "- The dataset is **large enough** to apply collaborative filtering and other models from class.  \n",
    "- Ratings may be skewed towards high values (common in review data).  \n",
    "- The dataset spans multiple years, so we can potentially do **time-based splits** (train on older, test on newer).  \n",
    "- The user–item matrix is very sparse, which motivates using **matrix factorization** and other latent-factor methods.\n",
    "\n",
    "We will use these observations to justify our **prediction task** and **feature choices**.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c11eb29",
   "metadata": {},
   "source": [
    "## 2. Predictive Task & Feature Engineering\n",
    "\n",
    "### 2.1 Predictive Task\n",
    "\n",
    "We define the following **binary classification task**:\n",
    "\n",
    "> Given a user and a recipe, predict whether the user will give a **high rating (≥ 4)** to that recipe.\n",
    "\n",
    "Formally, for each interaction `(user u, item i)` with rating `r`:\n",
    "- `y = 1` if `r ≥ 4`\n",
    "- `y = 0` otherwise\n",
    "\n",
    "This is a standard setup in recommender systems, interpreting ratings 4–5 as “liked” and ≤3 as “not liked / neutral”.\n",
    "\n",
    "We will evaluate our predictions using:\n",
    "- **Accuracy**\n",
    "- **AUC (Area Under ROC Curve)**\n",
    "- Optionally, **F1-score** for class-imbalance sensitivity.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a3ccee62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38094</td>\n",
       "      <td>40893</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1293707</td>\n",
       "      <td>40893</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8937</td>\n",
       "      <td>44394</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126440</td>\n",
       "      <td>85009</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57222</td>\n",
       "      <td>85009</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  recipe_id  rating  label\n",
       "0    38094      40893       4      1\n",
       "1  1293707      40893       5      1\n",
       "2     8937      44394       4      1\n",
       "3   126440      85009       5      1\n",
       "4    57222      85009       5      1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions[\"label\"] = (interactions[\"rating\"] >= 4).astype(int)\n",
    "interactions[[\"user_id\", \"recipe_id\", \"rating\", \"label\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a58be",
   "metadata": {},
   "source": [
    "### 2.2 Merging interactions with recipe metadata\n",
    "\n",
    "We join interactions with recipe metadata so we can build **content-based features** (recipe-level) and also support **collaborative filtering** (user–item IDs).\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eecea530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>calories</th>\n",
       "      <th>total_fat</th>\n",
       "      <th>sugar</th>\n",
       "      <th>sodium</th>\n",
       "      <th>protein</th>\n",
       "      <th>sat_fat</th>\n",
       "      <th>carbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38094</td>\n",
       "      <td>40893</td>\n",
       "      <td>2003-02-17</td>\n",
       "      <td>4</td>\n",
       "      <td>Great with a salad. Cooked on top of stove for...</td>\n",
       "      <td>1</td>\n",
       "      <td>40893</td>\n",
       "      <td>495</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>204.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1293707</td>\n",
       "      <td>40893</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>5</td>\n",
       "      <td>So simple, so delicious! Great for chilly fall...</td>\n",
       "      <td>1</td>\n",
       "      <td>40893</td>\n",
       "      <td>495</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>204.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8937</td>\n",
       "      <td>44394</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>This worked very well and is EASY.  I used not...</td>\n",
       "      <td>1</td>\n",
       "      <td>44394</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>132.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126440</td>\n",
       "      <td>85009</td>\n",
       "      <td>2010-02-27</td>\n",
       "      <td>5</td>\n",
       "      <td>I made the Mexican topping and took it to bunk...</td>\n",
       "      <td>1</td>\n",
       "      <td>85009</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2786.2</td>\n",
       "      <td>342.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57222</td>\n",
       "      <td>85009</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>Made the cheddar bacon topping, adding a sprin...</td>\n",
       "      <td>1</td>\n",
       "      <td>85009</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2786.2</td>\n",
       "      <td>342.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  recipe_id       date  rating  \\\n",
       "0    38094      40893 2003-02-17       4   \n",
       "1  1293707      40893 2011-12-21       5   \n",
       "2     8937      44394 2002-12-01       4   \n",
       "3   126440      85009 2010-02-27       5   \n",
       "4    57222      85009 2011-10-01       5   \n",
       "\n",
       "                                              review  label     id  minutes  \\\n",
       "0  Great with a salad. Cooked on top of stove for...      1  40893      495   \n",
       "1  So simple, so delicious! Great for chilly fall...      1  40893      495   \n",
       "2  This worked very well and is EASY.  I used not...      1  44394       20   \n",
       "3  I made the Mexican topping and took it to bunk...      1  85009       10   \n",
       "4  Made the cheddar bacon topping, adding a sprin...      1  85009       10   \n",
       "\n",
       "   n_steps  n_ingredients  calories  total_fat  sugar  sodium  protein  \\\n",
       "0        4              9     204.8        5.0    9.0    26.0     24.0   \n",
       "1        4              9     204.8        5.0    9.0    26.0     24.0   \n",
       "2        5              4     132.3       11.0   39.0     5.0      4.0   \n",
       "3        3             13    2786.2      342.0  134.0   290.0    161.0   \n",
       "4        3             13    2786.2      342.0  134.0   290.0    161.0   \n",
       "\n",
       "   sat_fat  carbs  \n",
       "0      2.0   10.0  \n",
       "1      2.0   10.0  \n",
       "2     11.0    5.0  \n",
       "3    301.0   42.0  \n",
       "4    301.0   42.0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse nutrition field into separate columns\n",
    "# nutrition is a string like \"[calories, total_fat, sugar, sodium, protein, sat_fat, carbs]\"\n",
    "recipes[\"nutrition_list\"] = recipes[\"nutrition\"].apply(literal_eval)\n",
    "\n",
    "nutrition_cols = [\"calories\", \"total_fat\", \"sugar\", \"sodium\", \"protein\", \"sat_fat\", \"carbs\"]\n",
    "for i, col in enumerate(nutrition_cols):\n",
    "    recipes[col] = recipes[\"nutrition_list\"].apply(lambda x: x[i] if len(x) > i else np.nan)\n",
    "\n",
    "# Select recipe features of interest\n",
    "recipe_features = [\n",
    "    \"id\",              # recipe_id\n",
    "    \"minutes\",\n",
    "    \"n_steps\",\n",
    "    \"n_ingredients\",\n",
    "] + nutrition_cols\n",
    "\n",
    "recipes_small = recipes[recipe_features]\n",
    "\n",
    "# Merge\n",
    "df = interactions.merge(recipes_small, left_on=\"recipe_id\", right_on=\"id\", how=\"inner\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1f105c",
   "metadata": {},
   "source": [
    "### 2.3 Content-based feature matrix\n",
    "\n",
    "For the **content-based model**, we only use recipe features (no user IDs), so the same recipe always has the same predicted “likelihood of like”.  \n",
    "This gives a strong **non-personalized baseline**.\n",
    "\n",
    "We will use:\n",
    "- `minutes`\n",
    "- `n_steps`\n",
    "- `n_ingredients`\n",
    "- `calories`, `total_fat`, `sugar`, `sodium`, `protein`, `sat_fat`, `carbs`\n",
    "\n",
    "We fill missing values with 0 for simplicity.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "daf6f423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minutes</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>calories</th>\n",
       "      <th>total_fat</th>\n",
       "      <th>sugar</th>\n",
       "      <th>sodium</th>\n",
       "      <th>protein</th>\n",
       "      <th>sat_fat</th>\n",
       "      <th>carbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>495</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>204.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>495</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>204.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>132.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2786.2</td>\n",
       "      <td>342.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2786.2</td>\n",
       "      <td>342.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   minutes  n_steps  n_ingredients  calories  total_fat  sugar  sodium  \\\n",
       "0      495        4              9     204.8        5.0    9.0    26.0   \n",
       "1      495        4              9     204.8        5.0    9.0    26.0   \n",
       "2       20        5              4     132.3       11.0   39.0     5.0   \n",
       "3       10        3             13    2786.2      342.0  134.0   290.0   \n",
       "4       10        3             13    2786.2      342.0  134.0   290.0   \n",
       "\n",
       "   protein  sat_fat  carbs  \n",
       "0     24.0      2.0   10.0  \n",
       "1     24.0      2.0   10.0  \n",
       "2      4.0     11.0    5.0  \n",
       "3    161.0    301.0   42.0  \n",
       "4    161.0    301.0   42.0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_feature_cols = [\n",
    "    \"minutes\", \"n_steps\", \"n_ingredients\"\n",
    "] + nutrition_cols\n",
    "\n",
    "X_content = df[content_feature_cols].fillna(0)\n",
    "y = df[\"label\"].values\n",
    "\n",
    "X_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c12aa75",
   "metadata": {},
   "source": [
    "### 2.4 Train / validation / test split\n",
    "\n",
    "To assess validity and significance of our results, we split the data into **train, validation, and test** sets.\n",
    "\n",
    "- Train: used to fit the model  \n",
    "- Validation: used for model/parameter selection (if needed)  \n",
    "- Test: used for final evaluation  \n",
    "\n",
    "We start with a simple random split; later we could explore time-based splits.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "616fdcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(792656, 169855, 169856)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_c, X_temp_c, y_train, y_temp = train_test_split(\n",
    "    X_content, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_valid_c, X_test_c, y_valid, y_test = train_test_split(\n",
    "    X_temp_c, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "len(X_train_c), len(X_valid_c), len(X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bcd3c6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_c)\n",
    "X_valid_scaled = scaler.transform(X_valid_c)\n",
    "X_test_scaled = scaler.transform(X_test_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d20885b",
   "metadata": {},
   "source": [
    "## 3. Models & Evaluation\n",
    "\n",
    "We implement and compare:\n",
    "\n",
    "1. **Logistic Regression (Content-Based Baseline)**  \n",
    "   - Uses only recipe features (no user ID).  \n",
    "   - A standard **classification model from class**.  \n",
    "   - Answers: “Given the recipe’s properties, how likely is it to be liked on average?”\n",
    "\n",
    "2. **Matrix Factorization (Collaborative Filtering)**  \n",
    "   - Uses **user and item IDs** to learn low-dimensional embeddings.  \n",
    "   - Captures personalized preferences.  \n",
    "   - A standard **recommender model** from class.\n",
    "\n",
    "We evaluate both with **Accuracy** and **AUC** on the held-out test set, and we discuss:\n",
    "- Relevant baselines  \n",
    "- Feature representations  \n",
    "- Overfitting / scaling issues  \n",
    "- Noise / missing data considerations  \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a510535c",
   "metadata": {},
   "source": [
    "### 3.1 Model 1 – Logistic Regression (Content-Based)\n",
    "\n",
    "This is a **linear classifier**:\n",
    "\n",
    "\\[\n",
    "\\hat{y} = \\sigma(w^\\top x + b)\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( x \\) = recipe feature vector  \n",
    "- \\( w \\) = learned weights  \n",
    "- \\( \\sigma \\) = sigmoid function  \n",
    "\n",
    "We expect this to capture **global tendencies** (e.g., very long, high-calorie recipes might be rated differently), but it cannot personalize to individual users.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "480ac03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LR Default (no class weighting) ===\n",
      "Validation Accuracy: 0.886379559035648\n",
      "Validation AUC: 0.5198788612075813\n",
      "\n",
      "=== LR Balanced (class_weight='balanced') ===\n",
      "Validation Accuracy: 0.6061581937534957\n",
      "Validation AUC: 0.5201822080016409\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, classification_report\n",
    "\n",
    "# Version 1: Default (no class weighting)\n",
    "lr_default = LogisticRegression(max_iter=5000)\n",
    "lr_default.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Version 2: Balanced class weights\n",
    "lr_balanced = LogisticRegression(class_weight='balanced', max_iter=5000)\n",
    "lr_balanced.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Validation - Default\n",
    "valid_probs_default = lr_default.predict_proba(X_valid_scaled)[:, 1]\n",
    "valid_preds_default = (valid_probs_default >= 0.5).astype(int)\n",
    "print(\"=== LR Default (no class weighting) ===\")\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_valid, valid_preds_default))\n",
    "print(\"Validation AUC:\", roc_auc_score(y_valid, valid_probs_default))\n",
    "\n",
    "# Validation - Balanced\n",
    "valid_probs_balanced = lr_balanced.predict_proba(X_valid_scaled)[:, 1]\n",
    "valid_preds_balanced = (valid_probs_balanced >= 0.5).astype(int)\n",
    "print(\"\\n=== LR Balanced (class_weight='balanced') ===\")\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_valid, valid_preds_balanced))\n",
    "print(\"Validation AUC:\", roc_auc_score(y_valid, valid_probs_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3875bffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Trivial Baseline (always predict 1) ===\n",
      "Accuracy: 0.8864, AUC: 0.5000\n",
      "\n",
      "=== LR Default (Test) ===\n",
      "Accuracy: 0.8863978899773927\n",
      "AUC: 0.5228434205651878\n",
      "F1: 0.9397775364218569\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.00      0.00     19297\n",
      "           1       0.89      1.00      0.94    150559\n",
      "\n",
      "    accuracy                           0.89    169856\n",
      "   macro avg       0.78      0.50      0.47    169856\n",
      "weighted avg       0.86      0.89      0.83    169856\n",
      "\n",
      "=== LR Balanced (Test) ===\n",
      "Accuracy: 0.6041588168801808\n",
      "AUC: 0.523404789689351\n",
      "F1: 0.7382855986236211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.40      0.19     19297\n",
      "           1       0.89      0.63      0.74    150559\n",
      "\n",
      "    accuracy                           0.60    169856\n",
      "   macro avg       0.51      0.52      0.46    169856\n",
      "weighted avg       0.80      0.60      0.68    169856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trivial baseline\n",
    "trivial_acc = y_test.mean()\n",
    "print(\"=== Trivial Baseline (always predict 1) ===\")\n",
    "print(f\"Accuracy: {trivial_acc:.4f}, AUC: 0.5000\\n\")\n",
    "\n",
    "# Test - Default LR\n",
    "test_probs_default = lr_default.predict_proba(X_test_scaled)[:, 1]  # FIX: use scaled data\n",
    "test_preds_default = (test_probs_default >= 0.5).astype(int)\n",
    "print(\"=== LR Default (Test) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, test_preds_default))\n",
    "print(\"AUC:\", roc_auc_score(y_test, test_probs_default))\n",
    "print(\"F1:\", f1_score(y_test, test_preds_default))\n",
    "print(classification_report(y_test, test_preds_default))\n",
    "\n",
    "# Test - Balanced LR\n",
    "test_probs_balanced = lr_balanced.predict_proba(X_test_scaled)[:, 1]  # FIX: use scaled data\n",
    "test_preds_balanced = (test_probs_balanced >= 0.5).astype(int)\n",
    "print(\"=== LR Balanced (Test) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, test_preds_balanced))\n",
    "print(\"AUC:\", roc_auc_score(y_test, test_probs_balanced))\n",
    "print(\"F1:\", f1_score(y_test, test_preds_balanced))\n",
    "print(classification_report(y_test, test_preds_balanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236538f5",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "- This model is **fast and scalable** even on large datasets.  \n",
    "- It provides interpretable coefficients, which we’ll analyze in Section 5.  \n",
    "- It ignores user identity, so it fails to capture “user A likes spicy food, user B doesn’t”.\n",
    "\n",
    "Next, we move to a **collaborative filtering** model that incorporates user and item IDs.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312553f2",
   "metadata": {},
   "source": [
    "### 3.2 Preparing data for Matrix Factorization\n",
    "\n",
    "For MF, we need:\n",
    "- Integer-encoded `user_id`\n",
    "- Integer-encoded `recipe_id`\n",
    "- Binary label `y` (like vs not like)\n",
    "\n",
    "We will re-split the data into train/valid/test on the **full interaction data** with user and item IDs.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "571f8343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of encoded users: 226570\n",
      "Number of encoded items: 231637\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "df[\"user_idx\"] = user_encoder.fit_transform(df[\"user_id\"])\n",
    "df[\"item_idx\"] = item_encoder.fit_transform(df[\"recipe_id\"])\n",
    "\n",
    "n_users = df[\"user_idx\"].nunique()\n",
    "n_items = df[\"item_idx\"].nunique()\n",
    "\n",
    "print(\"Number of encoded users:\", n_users)\n",
    "print(\"Number of encoded items:\", n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ef868393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(792656, 169855, 169856)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create arrays for MF\n",
    "u_all = df[\"user_idx\"].values\n",
    "i_all = df[\"item_idx\"].values\n",
    "y_all = df[\"label\"].values\n",
    "\n",
    "u_train, u_temp, i_train, i_temp, y_train_cf, y_temp_cf = train_test_split(\n",
    "    u_all, i_all, y_all, test_size=0.3, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "u_valid, u_test, i_valid, i_test, y_valid_cf, y_test_cf = train_test_split(\n",
    "    u_temp, i_temp, y_temp_cf, test_size=0.5, random_state=42, stratify=y_temp_cf\n",
    ")\n",
    "\n",
    "len(u_train), len(u_valid), len(u_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7850cf51",
   "metadata": {},
   "source": [
    "### 3.3 Model 2 – Matrix Factorization (Collaborative Filtering)\n",
    "\n",
    "We implement a simple MF model using PyTorch:\n",
    "\n",
    "- Each user \\( u \\) has embedding vector \\( p_u \\in \\mathbb{R}^k \\).  \n",
    "- Each item \\( i \\) has embedding vector \\( q_i \\in \\mathbb{R}^k \\).  \n",
    "- Predicted probability of a “like”:\n",
    "\n",
    "\\[\n",
    "\\hat{y}_{ui} = \\sigma(p_u^\\top q_i)\n",
    "\\]\n",
    "\n",
    "We train with **binary cross-entropy loss**.\n",
    "\n",
    "This is the standard latent factor model from class, adapted for binary labels.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3c5e83b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "82c84885",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionDataset(Dataset):\n",
    "    def __init__(self, users, items, labels):\n",
    "        self.users = users\n",
    "        self.items = items\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.users[idx]).long(),\n",
    "            torch.tensor(self.items[idx]).long(),\n",
    "            torch.tensor(self.labels[idx]).float()\n",
    "        )\n",
    "\n",
    "train_dataset = InteractionDataset(u_train, i_train, y_train_cf)\n",
    "valid_dataset = InteractionDataset(u_valid, i_valid, y_valid_cf)\n",
    "test_dataset  = InteractionDataset(u_test,  i_test,  y_test_cf)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4096, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4096, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=4096, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1a2192d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFModel(nn.Module):\n",
    "    def __init__(self, n_users, n_items, k=32):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, k)\n",
    "        self.item_emb = nn.Embedding(n_items, k)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # Optional: initialize embeddings\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
    "\n",
    "    def forward(self, u, i):\n",
    "        u_vec = self.user_emb(u)\n",
    "        i_vec = self.item_emb(i)\n",
    "        dot = (u_vec * i_vec).sum(dim=1)\n",
    "        return self.sigmoid(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "be9182d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MFModel(n_users=n_users, n_items=n_items, k=32).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bf8aef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mf(model, data_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for u, it, labels in data_loader:\n",
    "            u = u.to(device)\n",
    "            it = it.to(device)\n",
    "            labels = labels.to(device)\n",
    "            probs = model(u, it)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    preds = (all_probs >= 0.5).astype(int)\n",
    "\n",
    "    acc = accuracy_score(all_labels, preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    f1  = f1_score(all_labels, preds)\n",
    "    return acc, auc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "92f6a16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 120.6273 | Valid Acc: 0.7553 | Valid AUC: 0.6769 | Valid F1: 0.8541\n",
      "Epoch 02 | Train Loss: 53.4975 | Valid Acc: 0.7786 | Valid AUC: 0.7053 | Valid F1: 0.8700\n",
      "Epoch 03 | Train Loss: 15.2846 | Valid Acc: 0.7742 | Valid AUC: 0.7011 | Valid F1: 0.8669\n",
      "Epoch 04 | Train Loss: 4.8210 | Valid Acc: 0.7724 | Valid AUC: 0.6985 | Valid F1: 0.8657\n",
      "Epoch 05 | Train Loss: 2.1446 | Valid Acc: 0.7719 | Valid AUC: 0.6974 | Valid F1: 0.8654\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5  # you can increase this if training is fast\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for u, it, labels in train_loader:\n",
    "        u = u.to(device)\n",
    "        it = it.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        probs = model(u, it)\n",
    "        loss = criterion(probs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    val_acc, val_auc, val_f1 = evaluate_mf(model, valid_loader)\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {total_loss:.4f} | \"\n",
    "          f\"Valid Acc: {val_acc:.4f} | Valid AUC: {val_auc:.4f} | Valid F1: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "772c5e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF (Test) Accuracy: 0.7706939996232103\n",
      "MF (Test) AUC: 0.6937231360920842\n",
      "MF (Test) F1: 0.8645840938722295\n"
     ]
    }
   ],
   "source": [
    "test_acc_mf, test_auc_mf, test_f1_mf = evaluate_mf(model, test_loader)\n",
    "print(\"MF (Test) Accuracy:\", test_acc_mf)\n",
    "print(\"MF (Test) AUC:\", test_auc_mf)\n",
    "print(\"MF (Test) F1:\", test_f1_mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rosb4y1zbs",
   "metadata": {},
   "source": [
    "### 3.4 Model 3 – Latent Factor Model with Biases\n",
    "\n",
    "We extend the basic MF model by adding **bias terms**, which is a standard improvement in recommender systems:\n",
    "\n",
    "\\[\n",
    "\\hat{y}_{ui} = \\sigma(\\alpha + \\beta_u + \\beta_i + p_u^\\top q_i)\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( \\alpha \\) = global bias (overall tendency to like)\n",
    "- \\( \\beta_u \\) = user bias (some users rate higher than others)\n",
    "- \\( \\beta_i \\) = item bias (some recipes are universally liked/disliked)\n",
    "- \\( p_u, q_i \\) = latent factor vectors (personalized preferences)\n",
    "\n",
    "This model captures:\n",
    "1. **Global popularity**: Some items are just more popular overall\n",
    "2. **User tendencies**: Some users are \"easy graders\"\n",
    "3. **Personalization**: User-item specific preferences via dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0mongw06lvt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF with Biases - Parameters: 15,120,832\n"
     ]
    }
   ],
   "source": [
    "class MFModelWithBias(nn.Module):\n",
    "    \"\"\"Matrix Factorization with user and item biases\"\"\"\n",
    "    def __init__(self, n_users, n_items, k=32):\n",
    "        super().__init__()\n",
    "        # Latent factors\n",
    "        self.user_emb = nn.Embedding(n_users, k)\n",
    "        self.item_emb = nn.Embedding(n_items, k)\n",
    "        \n",
    "        # Bias terms\n",
    "        self.global_bias = nn.Parameter(torch.zeros(1))\n",
    "        self.user_bias = nn.Embedding(n_users, 1)\n",
    "        self.item_bias = nn.Embedding(n_items, 1)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # Initialize\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
    "        nn.init.zeros_(self.user_bias.weight)\n",
    "        nn.init.zeros_(self.item_bias.weight)\n",
    "\n",
    "    def forward(self, u, i):\n",
    "        # Latent factor dot product\n",
    "        u_vec = self.user_emb(u)\n",
    "        i_vec = self.item_emb(i)\n",
    "        dot = (u_vec * i_vec).sum(dim=1)\n",
    "        \n",
    "        # Add biases\n",
    "        u_bias = self.user_bias(u).squeeze()\n",
    "        i_bias = self.item_bias(i).squeeze()\n",
    "        \n",
    "        logit = self.global_bias + u_bias + i_bias + dot\n",
    "        return self.sigmoid(logit)\n",
    "\n",
    "# Initialize model\n",
    "model_bias = MFModelWithBias(n_users=n_users, n_items=n_items, k=32).to(device)\n",
    "optimizer_bias = torch.optim.Adam(model_bias.parameters(), lr=0.01)\n",
    "criterion_bias = nn.BCELoss()\n",
    "\n",
    "print(f\"MF with Biases - Parameters: {sum(p.numel() for p in model_bias.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "hrlgy20c245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 80.9599 | Valid Acc: 0.8866 | Valid AUC: 0.7474 | Valid F1: 0.9399\n",
      "Epoch 02 | Train Loss: 39.2973 | Valid Acc: 0.8798 | Valid AUC: 0.7336 | Valid F1: 0.9358\n",
      "Epoch 03 | Train Loss: 9.3935 | Valid Acc: 0.8698 | Valid AUC: 0.7219 | Valid F1: 0.9299\n",
      "Epoch 04 | Train Loss: 2.4119 | Valid Acc: 0.8671 | Valid AUC: 0.7189 | Valid F1: 0.9283\n",
      "Epoch 05 | Train Loss: 1.1262 | Valid Acc: 0.8655 | Valid AUC: 0.7172 | Valid F1: 0.9273\n"
     ]
    }
   ],
   "source": [
    "# Training loop for MF with Biases\n",
    "n_epochs_bias = 5\n",
    "\n",
    "for epoch in range(1, n_epochs_bias + 1):\n",
    "    model_bias.train()\n",
    "    total_loss = 0.0\n",
    "    for u, it, labels in train_loader:\n",
    "        u = u.to(device)\n",
    "        it = it.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer_bias.zero_grad()\n",
    "        probs = model_bias(u, it)\n",
    "        loss = criterion_bias(probs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_bias.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    val_acc, val_auc, val_f1 = evaluate_mf(model_bias, valid_loader)\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {total_loss:.4f} | \"\n",
    "          f\"Valid Acc: {val_acc:.4f} | Valid AUC: {val_auc:.4f} | Valid F1: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "14tg1jp68mm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MF with Biases (Test) ===\n",
      "Accuracy: 0.8651975791258478\n",
      "AUC: 0.7144586538730106\n",
      "F1: 0.9271285855682965\n",
      "\n",
      "Learned global bias: 1.0436\n",
      "(Sigmoid of global bias = 0.7395)\n"
     ]
    }
   ],
   "source": [
    "# Test evaluation for MF with Biases\n",
    "test_acc_mf_bias, test_auc_mf_bias, test_f1_mf_bias = evaluate_mf(model_bias, test_loader)\n",
    "print(\"=== MF with Biases (Test) ===\")\n",
    "print(\"Accuracy:\", test_acc_mf_bias)\n",
    "print(\"AUC:\", test_auc_mf_bias)\n",
    "print(\"F1:\", test_f1_mf_bias)\n",
    "\n",
    "# Also print the learned global bias\n",
    "print(f\"\\nLearned global bias: {model_bias.global_bias.item():.4f}\")\n",
    "print(f\"(Sigmoid of global bias = {torch.sigmoid(model_bias.global_bias).item():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b1672",
   "metadata": {},
   "source": [
    "### 3.5 Model Comparison Summary\n",
    "\n",
    "We compare all models on the test set:\n",
    "\n",
    "| Model                          | Accuracy | AUC    | F1     | Notes |\n",
    "|--------------------------------|----------|--------|--------|-------|\n",
    "| Trivial Baseline (predict 1)   | 88.64%   | 0.500  | -      | No learning |\n",
    "| Logistic Regression (Default)  | 88.64%   | 0.523  | 0.94   | Content-only, non-personalized |\n",
    "| Logistic Regression (Balanced) | 60.42%   | 0.523  | 0.74   | Better minority class detection |\n",
    "| Matrix Factorization           | 77.07%   | 0.694  | 0.86   | Personalized via embeddings |\n",
    "| **MF with Biases**             | **86.52%** | **0.714** | **0.93** | Best AUC, + bias terms |\n",
    "\n",
    "**Key observations:**\n",
    "1. **Content features are weak predictors**: LR achieves AUC ~0.52, barely above random (0.50). Recipe properties alone don't determine if a user will like it.\n",
    "2. **Personalization matters**: MF significantly outperforms LR in AUC (0.694 vs 0.523), showing user preferences are more predictive than recipe features.\n",
    "3. **Biases improve MF**: Adding user/item biases improves AUC from 0.694 to 0.714 and accuracy from 77% to 86.5%. The learned global bias (0.74 after sigmoid) captures the dataset's positive skew.\n",
    "4. **Class imbalance caveat**: High accuracy can be misleading—LR Default matches the trivial baseline accuracy (88.64%) but has marginally better AUC.\n",
    "\n",
    "**Discussion points:**\n",
    "- LR cannot personalize—it predicts the same probability for the same recipe regardless of user\n",
    "- MF captures user preferences but ignores recipe content\n",
    "- MF with Biases combines global popularity (item bias), user tendencies (user bias), and personalization (latent factors)\n",
    "- A hybrid approach combining content features with CF could potentially improve further"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14c4ff2",
   "metadata": {},
   "source": [
    "## 4. Related Literature\n",
    "\n",
    "### 4.1 Dataset Source and Prior Work\n",
    "\n",
    "The **Food.com Recipes and Interactions** dataset was introduced by Majumder et al. in their EMNLP 2019 paper:\n",
    "\n",
    "> Majumder, B. P., Li, S., Ni, J., & McAuley, J. (2019). *Generating Personalized Recipes from Historical User Preferences*. EMNLP 2019.\n",
    "\n",
    "In their work, the authors used this dataset for **personalized recipe generation**—given a user's history, generate new recipes tailored to their preferences. This is a more complex task than our binary classification (predict like/dislike), but demonstrates the rich user preference signals in this data.\n",
    "\n",
    "### 4.2 Similar Datasets and Tasks\n",
    "\n",
    "McAuley's Recommender Systems Datasets page hosts several similar review datasets:\n",
    "- **Amazon Product Reviews**: Product recommendations with ratings 1-5, text reviews, and product metadata\n",
    "- **BeerAdvocate / RateBeer**: Beer ratings with multi-aspect scores (appearance, aroma, taste, etc.)\n",
    "- **Steam Video Games**: Game recommendations with play hours and binary recommend/not-recommend\n",
    "\n",
    "These datasets have been used for:\n",
    "- **Rating prediction**: Predict the exact rating (regression) or rating class (classification)\n",
    "- **Top-N recommendation**: Rank items for each user\n",
    "- **Review generation**: Generate natural language explanations for recommendations\n",
    "\n",
    "### 4.3 Relevant Methods from Class\n",
    "\n",
    "Our implementation draws on classic recommender system techniques covered in CSE 158:\n",
    "\n",
    "**Logistic Regression (Content-Based Filtering)**\n",
    "- Uses item features to predict ratings without personalization\n",
    "- Covered in Weeks 1-2 of class (classification fundamentals)\n",
    "- Limitation: Same prediction for all users given the same item\n",
    "\n",
    "**Matrix Factorization (Collaborative Filtering)**\n",
    "- Koren, Y., Bell, R., & Volinsky, C. (2009). *Matrix Factorization Techniques for Recommender Systems*. IEEE Computer.\n",
    "- Learns latent factors for users and items from the interaction matrix\n",
    "- The Netflix Prize winning approach that demonstrated the power of latent factor models\n",
    "\n",
    "**Matrix Factorization with Biases**\n",
    "- Extends basic MF with global, user, and item bias terms\n",
    "- Captures that some users are \"easy graders\" and some items are universally popular\n",
    "- Standard improvement over basic MF, also from Koren et al.'s work\n",
    "\n",
    "### 4.4 State-of-the-Art Approaches (Beyond This Assignment)\n",
    "\n",
    "More advanced methods not implemented here include:\n",
    "- **Neural Collaborative Filtering (NCF)**: He et al., WWW 2017—replaces dot product with neural network\n",
    "- **Factorization Machines**: Rendle, 2010—generalizes MF to include arbitrary features\n",
    "- **Hybrid Methods**: Combine content features with collaborative filtering\n",
    "- **Sequential Recommenders**: Model user preference evolution over time (e.g., SASRec, BERT4Rec)\n",
    "\n",
    "### 4.5 Connection to Our Work\n",
    "\n",
    "Our assignment implements simplified versions of classic methods:\n",
    "- **Logistic Regression**: Content-based baseline using recipe features (minutes, nutrition, complexity)\n",
    "- **Matrix Factorization**: Basic collaborative filtering with user/item embeddings\n",
    "- **MF with Biases**: Standard improvement adding bias terms\n",
    "\n",
    "We focus on binary classification (like vs. not like) rather than exact rating prediction, which is appropriate given the skewed rating distribution (89% ratings ≥ 4). Our goal is to understand the relative value of content features vs. personalization, not to achieve state-of-the-art performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eb53c6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Coefficients (Default model):\n",
      "\n",
      "n_steps          coeff = -0.0712\n",
      "carbs            coeff = -0.0550\n",
      "sugar            coeff = -0.0452\n",
      "calories         coeff = -0.0365\n",
      "n_ingredients    coeff = +0.0199\n",
      "total_fat        coeff = +0.0167\n",
      "sat_fat          coeff = +0.0091\n",
      "protein          coeff = -0.0021\n",
      "minutes          coeff = +0.0013\n",
      "sodium           coeff = +0.0004\n"
     ]
    }
   ],
   "source": [
    "# Coefficient analysis for LR Default (more interpretable without class reweighting)\n",
    "coef = lr_default.coef_[0]\n",
    "print(\"Logistic Regression Coefficients (Default model):\\n\")\n",
    "for name, c in sorted(zip(content_feature_cols, coef), key=lambda x: -abs(x[1])):\n",
    "    print(f\"{name:15s}  coeff = {c:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13fdf25",
   "metadata": {},
   "source": [
    "## 5. Results Interpretation & Conclusions\n",
    "\n",
    "### 5.1 Which Models Worked Best?\n",
    "\n",
    "**Performance Ranking (by AUC):**\n",
    "1. **MF with Biases** (AUC: 0.714) — Best overall discriminative ability\n",
    "2. **Matrix Factorization** (AUC: 0.694) — Strong personalization\n",
    "3. **Logistic Regression** (AUC: 0.523) — Barely above random (0.50)\n",
    "4. **Trivial Baseline** (AUC: 0.500) — No learning\n",
    "\n",
    "**Key Finding: Personalization dominates content features.**\n",
    "\n",
    "The ~0.19 AUC gap between MF (0.694) and LR (0.523) demonstrates that *who* rates a recipe matters far more than *what* the recipe contains. Recipe features like cooking time, calories, and number of ingredients explain almost nothing about whether a user will like it—different users simply have different preferences that cannot be captured by recipe metadata alone.\n",
    "\n",
    "**Why MF with Biases wins:**\n",
    "- Captures that ~89% of ratings are positive (global bias = 0.74 after sigmoid)\n",
    "- Models user-specific rating tendencies (some users are generous raters)\n",
    "- Models item-specific popularity (some recipes are universally liked)\n",
    "- Learns personalized user-item interactions via latent factors\n",
    "\n",
    "### 5.2 Interpretation of Model Parameters\n",
    "\n",
    "**Logistic Regression Coefficients:**\n",
    "\n",
    "From our analysis, the most influential features are:\n",
    "\n",
    "| Feature | Coefficient | Interpretation |\n",
    "|---------|-------------|----------------|\n",
    "| n_steps | -0.0712 | More complex recipes (more steps) → slightly lower ratings |\n",
    "| carbs | -0.0550 | Higher carb recipes → slightly lower ratings |\n",
    "| sugar | -0.0452 | Sweeter recipes → slightly lower ratings |\n",
    "| calories | -0.0365 | Higher calorie recipes → slightly lower ratings |\n",
    "| n_ingredients | +0.0199 | More ingredients → slightly higher ratings |\n",
    "| total_fat | +0.0167 | Higher fat → slightly higher ratings |\n",
    "\n",
    "However, all coefficients are small (< 0.1), confirming that content features are weak predictors. The model essentially learns that simpler, lower-carb recipes are marginally preferred on average—but these effects are tiny compared to individual user preferences.\n",
    "\n",
    "**MF with Biases Parameters:**\n",
    "- **Global bias (1.04)**: After sigmoid = 0.74, reflecting the overall positive skew in ratings\n",
    "- **User biases**: Capture that some users consistently rate higher/lower than average\n",
    "- **Item biases**: Capture that some recipes are universally popular regardless of user preferences\n",
    "- **Latent factors (k=32)**: Capture nuanced user-item compatibility that biases alone cannot explain\n",
    "\n",
    "### 5.3 Issues Encountered and Solutions\n",
    "\n",
    "**Preprocessing Challenges:**\n",
    "- **Nutrition parsing**: The `nutrition` column was stored as a string representation of a list. Used `literal_eval` to parse it into separate columns.\n",
    "- **Missing values**: Filled with 0 for simplicity; could explore median imputation or indicator variables.\n",
    "- **ID encoding**: Used `LabelEncoder` to map string user/item IDs to contiguous integers for embedding lookup.\n",
    "\n",
    "**Scaling Considerations:**\n",
    "- **Feature scaling**: Applied `StandardScaler` to content features for LR. Critical because features have vastly different scales (minutes: 0-10000+, calories: 0-5000+).\n",
    "- **Training time**: MF training (~5 epochs) took longer than LR due to PyTorch overhead, but both completed in reasonable time on CPU.\n",
    "- **Embedding dimension**: Used k=32 as a reasonable default; smaller k risks underfitting, larger k risks overfitting with more parameters.\n",
    "\n",
    "**Class Imbalance:**\n",
    "- **Problem**: 89% positive class means a trivial \"always predict 1\" baseline achieves 88.64% accuracy.\n",
    "- **Solution**: Report AUC alongside accuracy. AUC measures ranking ability regardless of threshold and class distribution.\n",
    "- **Experiment**: Tried `class_weight='balanced'` in LR, which trades accuracy for better minority class detection but doesn't improve AUC.\n",
    "\n",
    "**Overfitting Observations:**\n",
    "- MF validation AUC peaked at epoch 2 (0.705) and slightly decreased by epoch 5 (0.697), suggesting mild overfitting.\n",
    "- MF with Biases showed similar pattern: peak at epoch 1, gradual decrease after.\n",
    "- Could add L2 regularization (weight decay) or early stopping for production use.\n",
    "\n",
    "### 5.4 Final Conclusions\n",
    "\n",
    "In this assignment, we used the Food.com recipe and review dataset to study personalized rating prediction. We framed the problem as binary classification (high rating ≥ 4 vs. low rating < 4) and compared three approaches:\n",
    "\n",
    "1. **Logistic Regression (Content-Based)**: Uses only recipe features. Achieved AUC of 0.523—barely better than random guessing. This demonstrates that recipe properties (cooking time, nutrition, complexity) do not determine user satisfaction.\n",
    "\n",
    "2. **Matrix Factorization (Collaborative Filtering)**: Uses user-item interaction patterns. Achieved AUC of 0.694—a substantial improvement. This confirms that personalization is essential: different users have different tastes that cannot be inferred from recipe metadata.\n",
    "\n",
    "3. **MF with Biases**: Adds global, user, and item bias terms. Achieved the best AUC of 0.714 while also recovering high accuracy (86.5%). The biases capture systematic effects (overall positivity, user generosity, item popularity) while latent factors capture personalized preferences.\n",
    "\n",
    "**Main Takeaways:**\n",
    "- Recipe content features are weak predictors of user ratings—AUC ~0.52 vs. random 0.50\n",
    "- Personalization via collaborative filtering dramatically improves predictions\n",
    "- Adding bias terms to MF provides both better accuracy and better AUC\n",
    "- Class imbalance (89% positive) makes accuracy misleading; AUC is the better metric\n",
    "\n",
    "**Future Directions:**\n",
    "- Hybrid models combining content features with collaborative filtering\n",
    "- Using recipe text (ingredients, descriptions) via NLP embeddings\n",
    "- Time-aware models to capture preference drift\n",
    "- Cold-start handling for new users/items with few interactions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}